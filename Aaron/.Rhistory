dt_ <- read.csv("C:\Users\tillera\Downloads\training.csv")
dt_ <- read.csv("C:/Users/tillera/Downloads/training.csv")
str(dt_)
hist(dt_$id)
View(dt_)
tr_ <- subset(dt_,select=-c("id"))
tr_ <- dt[,-c("id")]
tr_ <- dt[,!c("id")]
tr_ <- dt[,-1]
tr_ <- dt)[,-1]
tr_ <- dt_[,-1]
View(tr_)
myModel <- lm(data = tr_,price~.)
View(dt_)
dt2_ <-  read.csv("C:/Users/tillera/Downloads/dev.csv")
ts_y <- dt2_[,2]
ts_y <- as.data.frame(dt2_[,2])
View(ts_y)
colnames(ts_y) <- "price"
View(ts_y)
ts_x <- dt2_[,-c(1,2)]
ts_y$prediction <- predict(myModel,ts_x)
View(ts_y)
plot(ts_y)
rmse(ts_y$price,ts_y$prediction)
sqrt( sum( (ts_y$prediction - ts_y$price)^2 , na.rm = TRUE ) / nrow(ts_y) )
dt_ <- read.csv("H:/26.0 Commercial Reporting/1. RT Pipeline/2016/AT - Account Credits 0x1bfaa1d34e5e246d/withGLACode_temp.csv")
View(dt_)
str(dt_)
x_ <- dt_[dt_$GLACCOUNTCODE >= 4212041001,]
View(x_)
x_ <- dt_[dt_$GLACCOUNTCODE == 4212041001,]
?rda
??rda
oct(31)
setwd("~/ADLA3/Aaron")
require(sqldf)
require(caret)
require(ggplot2)
require(h2o)
## Required Supporting Scripts ##
#################################
source("../utilities.r") # Utility functions and helpers.
source("../FE.r") # Feature engineering functions.
# Read in the original dataset.
dt_ <- read.csv("../prostate.csv")
# We have been told that all our features are numerical measurements and are rounded to the nearest integer. This already gives us some noise which makes it difficult to predict an outcome. Also given the mutlinomial nature this will be a difficult tast.
## Feature Engineering ##
#########################
# Look for some near zero variance predictors from the original dataset.
nzv <- caret::nearZeroVar(dt_[,- c(1,ncol(dt_))],saveMetrics = TRUE)
nzv
# We can see that we don't really have any zero variance predictors. Also all the features seem to have only about 30% unique data points out of the entire data set. The most frequent to the second most frequent value also seems to be spread across the feature space from around 1.2 to 1.1.
# This shows that the data is quite spread out. Unlikely that the features themselves would do anything.
# Next let's try to identify whether there are any linear dependancies between our features.
lc <- caret::findLinearCombos(dt_[,- c(1,ncol(dt_))])
lc
# As expected, there are no linear dependancies between our features.
# Before move any further, let's generate a test and training set for our models to train on and later validate how well the model generalized.
# To accomplish this we are going to use our utilities script. In this script the function PrepareTraining is what will be called.
# This function is essentially a wrapper function to the caret package's createDartaPartition method. The added functionality includes, it drops the ID column, and forces the response variable (Result) to take a factor form. The split also ensures that the training set response distribution and the test set response distribution is similar. Given that we have unbalanced classes, this is very important. The function returns a list, with embedded training and testing dataframes.
training <- Udf.Utilities.PrepareTraining(dt_)$training
testing <- Udf.Utilities.PrepareTraining(dt_)$testing
# Generally speaking, most algorithms, especially neural networks 0 scaled data. Why ? I don't know.
# To do this we are going to use a method called preProcess from the caret package. This is actually a robust method to apply center and scaling using the training set and apply the same scaling matrix to any unseen data. We will also input a YeoJohnson transformation as well.
# Get the pre processor.
fe.PreProcessor <- caret::preProcess(training,method = c("center","scale","YeoJohnson"))
## Step 1
# Use the preprocessor to transform the training and the test dataset. This preprocessor model will be used to transform all unseen data as well.
tr.csyj <- predict(fe.PreProcessor,training) # training set.
ts.csyj <- predict(fe.PreProcessor,testing) # testing set.
# Let's visualise the dataset using smoe principle component analysis to get the two major axis. We will again call on a wrapper from the utilities script to do the principle component analysis for us. Inside the Udf.Utilities.Prcomp method is a simple call to stats::prcomp method.
ggplot(Udf.Utilities.Prcomp(tr.csyj[,-ncol(tr.csyj)],nComps = 2)$components,aes(PC1,PC2,color = tr.csyj$Result)) + geom_point() + scale_color_discrete("Result") + ggtitle("Prostate Cancer (Centered Scaled) on Principle Components.")
source('~/ADLA3/Aaron/10008_Pipeline.R', echo=TRUE)
h2o.init(nthreads = -1)
h2_tr <- as.h2o(feed.training,"h2_tr")
h2_ts <- as.h2o(feed.testing,"h2_ts")
NN.Autoencoder <- h2o.deeplearning(
x = 1:(ncol(feed.training)-1),
training_frame = h2_tr,
hidden = c(33,23,13,3,2,3,13,23,33),
epochs = 600,
activation = "Tanh",
autoencoder = TRUE
)
tr_sup_ft <- h2o.deepfeatures(NN.Autoencoder,h2_tr,layer = 5)
pltData <- as.data.frame(tr_sup_ft)
ggplot(pltData,aes(pltData$DF.L5.C1,pltData$DF.L5.C2,color=feed.training$Result)) + geom_point()
plot_ly(x=pltData$DF.L3.C1,y=pltData$DF.L3.C2,z=pltData$DF.L3.C3, color = as.factor(feed.training$Result), mode = 'markers',type = "scatter3d",scale = 0.1)
ggplot(pltData,aes(pltData$DF.L5.C1,pltData$DF.L5.C2,color=feed.training$Result)) + geom_point() + xlab("AE L5 Neuron 1") + ylab("AE L5 Neuron 2") + ggtitle("Auto Encoder Hidden Layer Output 2-Neurons in Layer") + scale_color_discrete("Result")

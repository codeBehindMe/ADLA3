dt_ <- read.csv("C:\Users\tillera\Downloads\training.csv")
dt_ <- read.csv("C:/Users/tillera/Downloads/training.csv")
str(dt_)
hist(dt_$id)
View(dt_)
tr_ <- subset(dt_,select=-c("id"))
tr_ <- dt[,-c("id")]
tr_ <- dt[,!c("id")]
tr_ <- dt[,-1]
tr_ <- dt)[,-1]
tr_ <- dt_[,-1]
View(tr_)
myModel <- lm(data = tr_,price~.)
View(dt_)
dt2_ <-  read.csv("C:/Users/tillera/Downloads/dev.csv")
ts_y <- dt2_[,2]
ts_y <- as.data.frame(dt2_[,2])
View(ts_y)
colnames(ts_y) <- "price"
View(ts_y)
ts_x <- dt2_[,-c(1,2)]
ts_y$prediction <- predict(myModel,ts_x)
View(ts_y)
plot(ts_y)
rmse(ts_y$price,ts_y$prediction)
sqrt( sum( (ts_y$prediction - ts_y$price)^2 , na.rm = TRUE ) / nrow(ts_y) )
dt_ <- read.csv("H:/26.0 Commercial Reporting/1. RT Pipeline/2016/AT - Account Credits 0x1bfaa1d34e5e246d/withGLACode_temp.csv")
View(dt_)
str(dt_)
x_ <- dt_[dt_$GLACCOUNTCODE >= 4212041001,]
View(x_)
x_ <- dt_[dt_$GLACCOUNTCODE == 4212041001,]
?rda
??rda
oct(31)
setwd("~/ADLA3/Aaron")
source('~/ADLA3/Aaron/10008_Pipeline.R', echo=TRUE)
h2o.init(nthreads = -1)
h2_tr <- as.h2o(feed.training,"h2_tr")
h2_ts <- as.h2o(feed.testing,"h2_ts")
NN.Autoencoder <- h2o.deeplearning(
x = 1:(ncol(feed.training)-1),
training_frame = h2_tr,
hidden = c(33,23,13,3,2,3,13,23,33),
epochs = 600,
activation = "Tanh",
autoencoder = TRUE,
export_weights_and_biases = TRUE
)
h2o.saveModel(NN.Autoencoder,"AE")
tr_sup_ft <- h2o.deepfeatures(NN.Autoencoder,h2_tr,layer = 5)
pltData <- as.data.frame(tr_sup_ft)
ggplot(pltData,aes(pltData$DF.L5.C1,pltData$DF.L5.C2,color=feed.training$Result)) + geom_point()
plot_ly(x=pltData$DF.L5.C1,y=pltData$DF.L5.C2, color = as.factor(feed.training$Result), mode = 'markers',scale = 0.1)
require(plotly)
plot_ly(x=pltData$DF.L5.C1,y=pltData$DF.L5.C2, color = as.factor(feed.training$Result), mode = 'markers',scale = 0.1)
saveRDS(as.matrix(h2o.weights(NN.Autoencoder,1)))
saveRDS(as.matrix(h2o.weights(NN.Autoencoder,1)),"AEL1")
saveRDS(as.matrix(h2o.weights(NN.Autoencoder,2)),"AEL2")
saveRDS(as.matrix(h2o.weights(NN.Autoencoder,3)),"AEL3")
saveRDS(as.matrix(feed.training),"features")
as.matrix(h2o.weights(NN.Autoencoder,1) %*% t(as.matrix(feed.testing))
)
as.matrix(h2o.weights(NN.Autoencoder,1)) %*% t(as.matrix(feed.testing))
feed.training.deep <- BindDeepFeatures(feed.training[,-ncol(feed.training)],NN.Autoencoder)
BindDeepFeatures <- function(features,h2oEncoder){
# Attach the autoencoder features.
dFtMtx <- matrix(nrow = nrow(features),ncol = 13) # Genereate a container for the new features.
ftMtx_ <- as.matrix(features) # Cast input as matrix.
print("Binding Deep Features Input Features")
pb_ <- txtProgressBar(style = 3) # Progress bar.
for(i in 1:nrow(ftMtx_)){
# Drop down through teh layers.
tmp__ <- as.matrix(h2o.weights(h2oEncoder,1)) %*% ftMtx_[i,]
tmp__ <- as.matrix(h2o.weights(h2oEncoder,2)) %*% tmp__
tmp__ <- as.matrix(h2o.weights(h2oEncoder,3)) %*% tmp__
tmp__ <- t(tmp__) # Transpose
dFtMtx[i,] <- tmp__ # Concatenate
setTxtProgressBar(pb_,i/nrow(ftMtx_))
close(pb_)
}
boundMatrix_ <- cbind(ftMtx_,dFtMtx)
return(as.data.frame(boundMatrix_))
}
feed.training.deep <- BindDeepFeatures(feed.training[,-ncol(feed.training)],NN.Autoencoder)
feed.testing.deep <- BindDeepFeatures(feed.testing[,-ncol(feed.testing)],NN.Autoencoder)
feed.training.deep <- as.data.frame(cbind(feed.training.deep,training[,"Result"]))
colnames(feed.training.deep)[ncol(feed.training.deep)] <- "Result"
feed.training.deep[,"Result"] <- as.factor(feed.training.deep[,"Result"])
feed.testing.deep <- as.data.frame(cbind(feed.testing.deep,testing[,"Result"]))
colnames(feed.testing.deep)[ncol(feed.testing.deep)] <- "Result"
feed.testing.deep[,"Result"] <- as.factor(feed.testing.deep[,"Result"])
h2_tr <- as.h2o(feed.training.deep,"h2_tr")
h2_ts <- as.h2o(feed.testing.deep,"h2_ts")
dl_6 <- h2o.deeplearning(
x = 1:(ncol(h2_tr) - 1),
y = ncol(h2_tr),
training_frame = h2_tr,
validation_frame = h2_ts,
distribution = "multinomial",
activation = "Maxout",
hidden = c(300,400,300),
l2 = 1e-5,
epochs = 30,
nfolds = 10,
balance_classes = TRUE,
#  input_dropout_ratio = 0.1,
loss = "CrossEntropy",
classification_stop = 0.45,
variable_importances = TRUE
)
prd_6 <- h2o.predict(dl_6,h2_ts)
prd_6 <- as.data.frame(prd_6)
sum(as.numeric(prd_6$predict) == as.numeric(feed.testing.deep$Result))/599
dl_5 <- h2o.loadModel("C:\\Users\\tillera\\Documents\\ADLA3\\Aaron\\mdl5\\DeepLearning_model_R_1480549397405_8")
prd_5 <- h2o.predict(dl_5,h2_ts)
prd_5 <- as.data.frame(prd_5)
sum(as.numeric(prd_5$predict) == as.numeric(feed.testing.deep$Result))/599
dl_6 <- h2o.deeplearning(
x = 1:(ncol(h2_tr) - 1),
y = ncol(h2_tr),
training_frame = h2_tr,
validation_frame = h2_ts,
distribution = "multinomial",
activation = "MaxoutWithDropout",
hidden = c(400,400,400),
l2 = 1e-5,
epochs = 20,
nfolds = 10,
balance_classes = TRUE,
input_dropout_ratio = 0.1,
loss = "CrossEntropy",
classification_stop = 0.45,
variable_importances = TRUE
)
prd_6 <- h2o.predict(dl_6,h2_ts)
prd_6 <- as.data.frame(prd_6)
sum(as.numeric(prd_6$predict) == as.numeric(feed.testing.deep$Result))/599
dl_6 <- h2o.deeplearning(
x = 1:(ncol(h2_tr) - 1),
y = ncol(h2_tr),
training_frame = h2_tr,
validation_frame = h2_ts,
distribution = "multinomial",
activation = "MaxoutWithDropout",
hidden = c(400,500,400),
l2 = 1e-5,
epochs = 20,
nfolds = 10,
balance_classes = TRUE,
input_dropout_ratio = 0.1,
loss = "CrossEntropy",
classification_stop = 0.45,
variable_importances = TRUE
)
prd_6 <- h2o.predict(dl_6,h2_ts)
prd_6 <- as.data.frame(prd_6)
sum(as.numeric(prd_6$predict) == as.numeric(feed.testing.deep$Result))/599
h2o.saveModel(dl_6,"mdl6")
dl_7 <- h2o.deeplearning( # 38.9
x = 1:(ncol(h2_tr) - 1),
y = ncol(h2_tr),
training_frame = h2_tr,
validation_frame = h2_ts,
distribution = "multinomial",
activation = "MaxoutWithDropout",
hidden = c(400,500,400),
l2 = 1e-4,
epochs = 20,
nfolds = 10,
balance_classes = TRUE,
input_dropout_ratio = 0.1,
loss = "CrossEntropy",
classification_stop = 0.45,
variable_importances = TRUE
)
prd_7 <- h2o.predict(dl_7,h2_ts)
prd_7 <- as.data.frame(prd_7)
sum(as.numeric(prd_7$predict) == as.numeric(feed.testing.deep$Result))/599
h2o.saveModel(dl_7,"mdl7")
plot_ly(x=pltData$DF.L5.C1,y=pltData$DF.L5.C2, color = as.factor(feed.training$Result), mode = 'markers',scale = 0.1)
ggplot(pltData,aes(pltData$DF.L5.C1,pltData$DF.L5.C2,color=feed.training$Result)) + geom_point()
rm(dl_5)
rm_(dl_6)
rm(dl_6)
dl_8 <- h2o.deeplearning( # 39.2%
x = 1:(ncol(h2_tr) - 1),
y = ncol(h2_tr),
training_frame = h2_tr,
validation_frame = h2_ts,
distribution = "multinomial",
activation = "MaxoutWithDropout",
hidden = c(400,500,400),
l2 = 1e-3,
epochs = 20,
nfolds = 10,
balance_classes = TRUE,
input_dropout_ratio = 0.1,
loss = "CrossEntropy",
classification_stop = 0.45,
variable_importances = TRUE
)
prd_8 <- h2o.predict(dl_8,h2_ts)
prd_8 <- as.data.frame(prd_8)
sum(as.numeric(prd_8$predict) == as.numeric(feed.testing.deep$Result))/599
h2o.saveModel(dl_8,"mdl8")
